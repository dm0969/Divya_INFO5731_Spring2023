{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dm0969/Divya_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023_divya_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hznInHvjq6gR"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xptphq2q6gU"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6rZZxijq6gU"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3B3QaCaq6gV"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "I chose the topic of movies because it's engaging, and selecting or rating a good movie requires considering many different viewpoints and being aware of certain details.\n",
        "I am compiling the reviews for films. I have gathered ratings and reviews.\n",
        "To extract data, the Beautifulsoap library is used.\n",
        "\n",
        "A class is used to extract the data, which is then put into a list before being converted into a dataframe.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwxZlodbq6gW"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ3x7wlAq6gW",
        "outputId": "3fdded8f-ced4-4825-afb3-79c37e07181b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.imdb.com/title/tt14826022/reviews', 'https://www.imdb.com/title/tt10640346/reviews', 'https://www.imdb.com/title/tt9114286/reviews', 'https://www.imdb.com/title/tt1630029/reviews', 'https://www.imdb.com/title/tt9764362/reviews', 'https://www.imdb.com/title/tt9686790/reviews', 'https://www.imdb.com/title/tt11813216/reviews', 'https://www.imdb.com/title/tt6710474/reviews', 'https://www.imdb.com/title/tt15679400/reviews', 'https://www.imdb.com/title/tt8760708/reviews', 'https://www.imdb.com/title/tt10365998/reviews', 'https://www.imdb.com/title/tt15486810/reviews', 'https://www.imdb.com/title/tt12844910/reviews', 'https://www.imdb.com/title/tt3915174/reviews', 'https://www.imdb.com/title/tt5884796/reviews', 'https://www.imdb.com/title/tt14444726/reviews', 'https://www.imdb.com/title/tt14208870/reviews', 'https://www.imdb.com/title/tt11564570/reviews', 'https://www.imdb.com/title/tt3704428/reviews', 'https://www.imdb.com/title/tt13833688/reviews', 'https://www.imdb.com/title/tt1016150/reviews', 'https://www.imdb.com/title/tt7322224/reviews', 'https://www.imdb.com/title/tt7405458/reviews', 'https://www.imdb.com/title/tt14138650/reviews', 'https://www.imdb.com/title/tt13560574/reviews', 'https://www.imdb.com/title/tt18079362/reviews', 'https://www.imdb.com/title/tt15255288/reviews', 'https://www.imdb.com/title/tt19770238/reviews', 'https://www.imdb.com/title/tt1745960/reviews', 'https://www.imdb.com/title/tt12593682/reviews', 'https://www.imdb.com/title/tt0107048/reviews', 'https://www.imdb.com/title/tt14209916/reviews', 'https://www.imdb.com/title/tt9737876/reviews', 'https://www.imdb.com/title/tt10954600/reviews', 'https://www.imdb.com/title/tt13539646/reviews', 'https://www.imdb.com/title/tt8129806/reviews', 'https://www.imdb.com/title/tt13669038/reviews', 'https://www.imdb.com/title/tt10151854/reviews', 'https://www.imdb.com/title/tt8946378/reviews', 'https://www.imdb.com/title/tt6718170/reviews', 'https://www.imdb.com/title/tt0499549/reviews', 'https://www.imdb.com/title/tt8041270/reviews', 'https://www.imdb.com/title/tt1877830/reviews', 'https://www.imdb.com/title/tt3427252/reviews', 'https://www.imdb.com/title/tt10304142/reviews', 'https://www.imdb.com/title/tt15600222/reviews', 'https://www.imdb.com/title/tt9411972/reviews', 'https://www.imdb.com/title/tt10855768/reviews', 'https://www.imdb.com/title/tt19623240/reviews', 'https://www.imdb.com/title/tt11976532/reviews']\n",
            "https://www.imdb.com/title/tt14826022/reviews\n",
            "https://www.imdb.com/title/tt10640346/reviews\n",
            "vote : 25 review list:25\n",
            "rating1:25\n",
            "vote : 50 review list:50\n",
            "rating1:50\n",
            "vote : 75 review list:75\n",
            "rating1:75\n",
            "vote : 100 review list:100\n",
            "rating1:100\n",
            "vote : 125 review list:125\n",
            "rating1:125\n",
            "vote : 150 review list:150\n",
            "rating1:150\n",
            "vote : 175 review list:175\n",
            "rating1:175\n",
            "vote : 200 review list:200\n",
            "rating1:200\n",
            "vote : 225 review list:225\n",
            "rating1:225\n",
            "vote : 250 review list:250\n",
            "rating1:250\n",
            "vote : 275 review list:275\n",
            "rating1:275\n",
            "vote : 300 review list:300\n",
            "rating1:300\n",
            "vote : 325 review list:325\n",
            "rating1:325\n",
            "vote : 350 review list:350\n",
            "rating1:350\n",
            "vote : 375 review list:375\n",
            "rating1:375\n",
            "vote : 400 review list:400\n",
            "rating1:400\n",
            "vote : 425 review list:425\n",
            "rating1:425\n",
            "vote : 450 review list:450\n",
            "rating1:450\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "urlTitle = 'https://www.imdb.com/search/title/?title_type=feature' \n",
        "req = requests.get(urlTitle)\n",
        "url_txt = BeautifulSoup(req.text, 'lxml') \n",
        "url_dm = url_txt.find_all('a', attrs={'class': None})\n",
        "url_dm_txt = [tag.attrs['href'] for tag in url_dm \n",
        "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
        "url_dm_txt = list(dict.fromkeys(url_dm_txt)) \n",
        "url_link = [\"https://www.imdb.com\" + tag + 'reviews' for tag in url_dm_txt]\n",
        "print(url_link)\n",
        "print(url_link[0])\n",
        "print(url_link[1])\n",
        "\n",
        "\n",
        "def getIndex(a):\n",
        "    minpos = a.index(min(a))\n",
        "    maxpos = a.index(max(a))\n",
        "    return minpos,maxpos\n",
        "\n",
        "comm = []\n",
        "votes = []\n",
        "vt=[]\n",
        "UID=[]\n",
        "cinema=[]\n",
        "review=[]\n",
        "for i in range(0,50):\n",
        "    url_txt = BeautifulSoup(requests.get(url_link[i]).text, 'html.parser')\n",
        "    Voting = [tag.previous_element for tag in \n",
        "                           url_txt.find_all('span', attrs={'class': 'point-scale'})]\n",
        "    if len(Voting) > 0:  \n",
        "        neg_index, pos_index = getIndex(list(map(int, Voting)))\n",
        "        review_list = url_txt.find_all('a', attrs={'class':'title'})\n",
        "        rev = [\"https://www.imdb.com\" + review['href'] for review in review_list]\n",
        "    else:\n",
        "        print(None)\n",
        "\n",
        "\n",
        "\n",
        "    for j in rev:\n",
        "        text=BeautifulSoup(requests.get(j).text, 'html.parser').find('div', attrs={'class': 'text show-more__control'}).get_text()\n",
        "        rating=BeautifulSoup(requests.get(j).text, 'html.parser').find('div', attrs={'class': 'lister-item-content'}).get_text()\n",
        "        movieuser=(BeautifulSoup(requests.get(j).text, 'html.parser').find('title').get_text())\n",
        "        description=(BeautifulSoup(requests.get(j).text, 'html.parser').find('a', attrs={'class': 'title'}).get_text())\n",
        "        len_rating=len(vt)\n",
        "        if(text == ''):\n",
        "            comm.append('No Review')\n",
        "        else:\n",
        "            comm.append(text)\n",
        "        votes.append(rating)\n",
        "\n",
        "        UID.append(movieuser.split(\"'s\")[0])\n",
        "        cinema.append(movieuser.split('Review of')[1])\n",
        "        review.append(description)\n",
        "  \n",
        "    print('vote : '+str(len(votes))+' review list:'+str(len(comm)))\n",
        "    if(len_rating==0):\n",
        "        k=0\n",
        "    else:\n",
        "        k=len_rating\n",
        "    for j in range(k,len(votes)):\n",
        "        vt.append(votes[j].split('/10')[0].split('\\n')[len(votes[j].split('/10')[0].split('\\n'))-1])\n",
        "    print('rating1:'+str(len(vt)))\n",
        "\n",
        "data_review = {\n",
        "        \"Cinema name\" : cinema,\n",
        "        \"User Name\" : UID,\n",
        "        \"Review_Note\" : review,\n",
        "        'Detail Reviews': comm,\n",
        "        'Rating': vt,\n",
        "        \n",
        "        }\n",
        "df = pd.DataFrame(data_review)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_ccq6-nq6gX"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMLWyiM7q6gX"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import json as js\n",
        "import urllib.request as req\n",
        "from bs4 import BeautifulSoup as beau\n",
        "\n",
        "with req.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as fr:\n",
        "    dm = fr.read()\n",
        "    st = beau(dm)\n",
        "    print(st.p.text)\n",
        "    with open('output.txt', 'w') as fw:\n",
        "        js.dump(st.p.text, fw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppVhPAr9q6gY"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_3BswjUq6gY"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n",
        "import json as js\n",
        "import urllib.request as req\n",
        "from bs4 import BeautifulSoup as beau\n",
        "\n",
        "with req.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as fR:\n",
        "    dm = fR.read()\n",
        "    st = beau(dm)\n",
        "    print(st.p.text)\n",
        "    with open('output.txt', 'w') as fW:\n",
        "        js.dump(st.p.text, fW)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}